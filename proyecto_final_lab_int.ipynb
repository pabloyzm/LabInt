{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto Final Área Imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import skimage.io\n",
    "from skimage.feature import local_binary_pattern\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "\n",
    "#from keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from skimage import transform\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Embedding\n",
    "from keras import backend as K\n",
    "\n",
    "from PIL import Image\n",
    "import os, os.path\n",
    "from tqdm import notebook\n",
    "from numba import jit\n",
    "\n",
    "\n",
    "\n",
    "def convnet_model_():\n",
    "    vgg_model = VGG16(weights=None, include_top=False)\n",
    "    x = vgg_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = Dropout(0.6)(x)\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = Dropout(0.6)(x)\n",
    "    x = Lambda(lambda  x: K.l2_normalize(x,axis=1))(x)\n",
    "    convnet_model = Model(inputs=vgg_model.input, outputs=x)\n",
    "    return convnet_model\n",
    "\n",
    "def convnet_model():\n",
    "\tvgg_model = VGG16(weights=None, include_top=False)\n",
    "\tx = vgg_model.output\n",
    "\tx - GlobalAveragePooling2D()(x)\n",
    "\tx = Dense(4096, activation='relu')(x)\n",
    "\tx = Dropout(0.6)(x)\n",
    "\tx = Dense(4096, activation='relu')(x)\n",
    "\tx = Dropout(0.6)(x)\n",
    "\n",
    "def deep_rank_model():\n",
    "\n",
    "    convnet_model = convnet_model_()\n",
    "    first_input = Input(shape=(224,224,3))\n",
    "    first_conv = Conv2D(96, kernel_size=(8, 8),strides=(16,16), padding='same')(first_input)\n",
    "    first_max = MaxPool2D(pool_size=(3,3),strides = (4,4),padding='same')(first_conv)\n",
    "    first_max = Flatten()(first_max)\n",
    "    first_max = Lambda(lambda  x: K.l2_normalize(x,axis=1))(first_max)\n",
    "\n",
    "    second_input = Input(shape=(224,224,3))\n",
    "    second_conv = Conv2D(96, kernel_size=(8, 8),strides=(32,32), padding='same')(second_input)\n",
    "    second_max = MaxPool2D(pool_size=(7,7),strides = (2,2),padding='same')(second_conv)\n",
    "    second_max = Flatten()(second_max)\n",
    "    second_max = Lambda(lambda  x: K.l2_normalize(x,axis=1))(second_max)\n",
    "\n",
    "    merge_one = concatenate([first_max, second_max])\n",
    "\n",
    "    merge_two = concatenate([merge_one, convnet_model.output])\n",
    "    emb = Dense(4096)(merge_two)\n",
    "    l2_norm_final = Lambda(lambda  x: K.l2_normalize(x,axis=1))(emb)\n",
    "\n",
    "    final_model = Model(inputs=[first_input, second_input, convnet_model.input], outputs=l2_norm_final)\n",
    "\n",
    "    return final_model\n",
    "\n",
    "\n",
    "model = deep_rank_model()\n",
    "\n",
    "for layer in model.layers:\n",
    "    print (layer.name, layer.output_shape)\n",
    "\n",
    "\n",
    "if not os.path.exists(\"./deepranking-v2-150000.h5\"):\n",
    "    print(\"No se encontró el modelo, se descargará\")\n",
    "    import gdown\n",
    "    url = 'https://drive.google.com/uc?id=1TmUKqp_TnzSP0TeAHIyTv8jG4KZeNqQP'\n",
    "    output = 'deepranking-v2-150000.h5'\n",
    "    gdown.download(url, output, quiet=False)\n",
    "\n",
    "model.load_weights(\"./deepranking-v2-150000.h5\")\n",
    "\n",
    "%%capture"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 1\n",
    "Vectores característicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def classic_method(image):\n",
    "    image = np.array(image)\n",
    "    #print(image.shape)\n",
    "    \"Implements LBP algorithm \"\n",
    "    lbp = local_binary_pattern(image, P=8, R=1)\n",
    "    #segmentar\n",
    "    ##corregir lbp para tamaǹo variable\n",
    "    #lbp = lbp[:500,:600] \n",
    "    #print(lbp.shape)\n",
    "    M = (lbp.shape[0])#//10\n",
    "    N = (lbp.shape[1])#//10\n",
    "    tiles = [lbp[x:x+M,y:y+N] for x in range(0,lbp.shape[0],M) for y in range(0,lbp.shape[1],N)]\n",
    "        \n",
    "    #segment histogramas  \n",
    "    tiles_histogram = []\n",
    "    #calcular el histograma para cada segmento\n",
    "    for i in (tiles): \n",
    "        hist = np.histogram(i,density=True,bins = 59,range=(0, 59))[0]\n",
    "        tiles_histogram.append(hist)\n",
    "    full_histogram = np.array(tiles_histogram).flatten()\n",
    "    return np.array(full_histogram) \n",
    "\n",
    "\n",
    "def load_and_process(paths = ['data/GPR1200/images/'], valid_types = [\".jpg\",\".JPEG\"]):\n",
    "    \"\"\" load and process saves memory by only saving the vectorized image and not the image itself\"\"\"\n",
    "    hists = []\n",
    "\n",
    "    for i in range(len(paths)):\n",
    "        list_dir = notebook.tqdm(os.listdir(paths[i]))\n",
    "        \n",
    "        for f in list_dir:\n",
    "            list_dir.set_description(f\"Loading images from directory {paths[i]}\")\n",
    "            ext = os.path.splitext(f)[1]\n",
    "            \n",
    "            if ext.lower() not in valid_types:\n",
    "                continue\n",
    "            image = (Image.open(os.path.join(paths[i],f)).convert('L'))\n",
    "            hist = classic_method(image)\n",
    "            hists.append(hist)\n",
    "    return hists\n",
    "\n",
    "def CNN_method(image1):\n",
    "    image1 = img_to_array(image1).astype(\"float64\")\n",
    "    image1 = transform.resize(image1, (224, 224))\n",
    "    image1 *= 1. / 255\n",
    "    image1 = np.expand_dims(image1, axis = 0)\n",
    "    return model.predict([image1, image1, image1])[0]\n",
    "\n",
    "def get_vector(image, extractor_type):\n",
    "    \n",
    "    if extractor_type == 'classic':\n",
    "        vector = classic_method(image)\n",
    "    else:\n",
    "        vector =CNN_method(image)\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_and_process()\n",
    "pd.DataFrame(img).to_csv(\"vectors/vectorized_images_classic.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_metric(vec_1,vec_2, measure = 'euclidean'):\n",
    "    if measure == 'euclidean':\n",
    "        resta = vec_1 - vec_2\n",
    "        return np.sqrt(np.sum(resta**2))\n",
    "    elif measure == 'manhattan':\n",
    "        resta = vec_1 - vec_2\n",
    "        return np.sum(np.abs(resta))\n",
    "    elif measure == 'cosine':\n",
    "        dot_product = np.dot(vec_1, vec_2)\n",
    "        norm_a = np.linalg.norm(vec_1)\n",
    "        norm_b = np.linalg.norm(vec_2)\n",
    "        cosine_similarity = dot_product / (norm_a * norm_b)\n",
    "        return 1 - cosine_similarity\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown measure: {measure}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(image, img_database):\n",
    "    pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relevance_ranking(compare_list):\n",
    "    n = len(compare_list)\n",
    "    rank = (1/n)* np.sum(compare_list)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_rank(RETURN_FUNCION_ARRIBA,method):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
