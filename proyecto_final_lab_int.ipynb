{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto Final Área Imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import io\n",
    "from skimage import local_binary_pattern\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "#from keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from skimage import transform\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Embedding\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def convnet_model_():\n",
    "    vgg_model = VGG16(weights=None, include_top=False)\n",
    "    x = vgg_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = Dropout(0.6)(x)\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = Dropout(0.6)(x)\n",
    "    x = Lambda(lambda  x: K.l2_normalize(x,axis=1))(x)\n",
    "    convnet_model = Model(inputs=vgg_model.input, outputs=x)\n",
    "    return convnet_model\n",
    "\n",
    "def convnet_model():\n",
    "\tvgg_model = VGG16(weights=None, include_top=False)\n",
    "\tx = vgg_model.output\n",
    "\tx - GlobalAveragePooling2D()(x)\n",
    "\tx = Dense(4096, activation='relu')(x)\n",
    "\tx = Dropout(0.6)(x)\n",
    "\tx = Dense(4096, activation='relu')(x)\n",
    "\tx = Dropout(0.6)(x)\n",
    "\n",
    "def deep_rank_model():\n",
    "\n",
    "    convnet_model = convnet_model_()\n",
    "    first_input = Input(shape=(224,224,3))\n",
    "    first_conv = Conv2D(96, kernel_size=(8, 8),strides=(16,16), padding='same')(first_input)\n",
    "    first_max = MaxPool2D(pool_size=(3,3),strides = (4,4),padding='same')(first_conv)\n",
    "    first_max = Flatten()(first_max)\n",
    "    first_max = Lambda(lambda  x: K.l2_normalize(x,axis=1))(first_max)\n",
    "\n",
    "    second_input = Input(shape=(224,224,3))\n",
    "    second_conv = Conv2D(96, kernel_size=(8, 8),strides=(32,32), padding='same')(second_input)\n",
    "    second_max = MaxPool2D(pool_size=(7,7),strides = (2,2),padding='same')(second_conv)\n",
    "    second_max = Flatten()(second_max)\n",
    "    second_max = Lambda(lambda  x: K.l2_normalize(x,axis=1))(second_max)\n",
    "\n",
    "    merge_one = concatenate([first_max, second_max])\n",
    "\n",
    "    merge_two = concatenate([merge_one, convnet_model.output])\n",
    "    emb = Dense(4096)(merge_two)\n",
    "    l2_norm_final = Lambda(lambda  x: K.l2_normalize(x,axis=1))(emb)\n",
    "\n",
    "    final_model = Model(inputs=[first_input, second_input, convnet_model.input], outputs=l2_norm_final)\n",
    "\n",
    "    return final_model\n",
    "\n",
    "\n",
    "model = deep_rank_model()\n",
    "\n",
    "for layer in model.layers:\n",
    "    print (layer.name, layer.output_shape)\n",
    "\n",
    "\n",
    "if not os.path.exists(\"./deepranking-v2-150000.h5\"):\n",
    "    print(\"No se encontró el modelo, se descargará\")\n",
    "    import gdown\n",
    "    url = 'https://drive.google.com/uc?id=1TmUKqp_TnzSP0TeAHIyTv8jG4KZeNqQP'\n",
    "    output = 'deepranking-v2-150000.h5'\n",
    "    gdown.download(url, output, quiet=False)\n",
    "\n",
    "model.load_weights(\"./deepranking-v2-150000.h5\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DATASET = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(path):\n",
    "    \"\"\"Loads images from path\"\"\"\n",
    "    imgs = []\n",
    "    names = os.listdir(path)\n",
    "\n",
    "    for name in names: \n",
    "        image = io.imread(fname=os.path.join(path,name))\n",
    "        imgs.append(image) \n",
    "    return np.array(imgs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 1\n",
    "Vectores característicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classic_method(image):\n",
    "    \"Implements LBP algorithm \"\n",
    "    lbp = local_binary_pattern(image, P=8, R=1)\n",
    "    #segmentar\n",
    "    lbp = lbp[:500,:600] \n",
    "    M = (lbp.shape[0])//5\n",
    "    N = (lbp.shape[1])//5\n",
    "    tiles = [lbp[x:x+M,y:y+N] for x in range(0,lbp.shape[0],M) for y in range(0,lbp.shape[1],N)]\n",
    "        \n",
    "    #segment histogramas  \n",
    "    tiles_histogram = []\n",
    "    #calcular el histograma para cada segmento\n",
    "    for i in tiles: \n",
    "        hist = np.histogram(i.ravel(),density=True,bins = 59,range=(0, 59))[0]\n",
    "        tiles_histogram.append(hist)\n",
    "    full_histogram = np.array(tiles_histogram).flatten()\n",
    "    return np.array(full_histogram) \n",
    "    \n",
    "\n",
    "\n",
    "def CNN_method(image1):\n",
    "    image1 = img_to_array(image1).astype(\"float64\")\n",
    "    image1 = transform.resize(image1, (224, 224))\n",
    "    image1 *= 1. / 255\n",
    "    image1 = np.expand_dims(image1, axis = 0)\n",
    "    return model.predict([image1, image1, image1])[0]\n",
    "\n",
    "def get_vector(image, extractor_type):\n",
    "    \n",
    "    if extractor_type == 'classic':\n",
    "        vector = classic_method(image)\n",
    "    else:\n",
    "        vector =CNN_method(image)\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_metric(vec_1,vec_2, measure = 'euclidean'):\n",
    "    if measure == 'euclidean':\n",
    "        resta = vec_1 - vec_2\n",
    "        return np.sqrt(np.sum(resta**2))\n",
    "    elif measure == 'manhattan':\n",
    "        resta = vec_1 - vec_2\n",
    "        return np.sum(np.abs(resta))\n",
    "    elif measure == 'cosine':\n",
    "        dot_product = np.dot(vec_1, vec_2)\n",
    "        norm_a = np.linalg.norm(vec_1)\n",
    "        norm_b = np.linalg.norm(vec_2)\n",
    "        cosine_similarity = dot_product / (norm_a * norm_b)\n",
    "        return 1 - cosine_similarity\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown measure: {measure}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(image, img_database):\n",
    "    pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relevance_ranking(compare_list):\n",
    "    n = len(compare_list)\n",
    "    rank = (1/n)* np.sum(compare_list)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_rank(RETURN_FUNCION_ARRIBA,method):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
